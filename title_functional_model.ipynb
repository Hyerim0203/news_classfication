{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "title_functional_model",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RG32Ww18y_wL"
      },
      "source": [
        "# title을 예측하는 model 생성"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G58ACtrdsChc",
        "outputId": "b85d8707-697e-4b55-c1aa-1917ed21a49e"
      },
      "source": [
        "# 내 드라이브에 대한 주소\r\n",
        "from google.colab import drive\r\n",
        "drive.mount('/gdrive', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XjAbrIbgstaw"
      },
      "source": [
        "# konlpy Mecab 사용하기\r\n",
        "\r\n",
        "!set -x \\\r\n",
        "&& pip install konlpy \\\r\n",
        "&& curl -s https://raw.githubusercontent.com/konlpy/konlpy/master/scripts/mecab.sh | bash -x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xH9XAIwVNM6i"
      },
      "source": [
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "import tensorflow as tf\r\n",
        "from tensorflow import keras\r\n",
        "import seaborn as sns\r\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "thhr8jLXzY8F"
      },
      "source": [
        "path = \"/gdrive/My Drive/\"\r\n",
        "\r\n",
        "train = pd.read_csv(path+\"news_train.csv\")\r\n",
        "#test = pd.read_csv(path+\"news_test.csv\")\r\n",
        "submission = pd.read_csv(path + \"sample_submission.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xYNgASw3Lpvh",
        "outputId": "06bf5f0e-1fd1-44cc-de58-638a97c06c33"
      },
      "source": [
        "print(train.shape)\r\n",
        "#print(test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(118745, 6)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JTH3wWj3yqzI"
      },
      "source": [
        "# 텍스트 전처리"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v2-dlVSksy0L"
      },
      "source": [
        "from konlpy.tag import Mecab\r\n",
        "import re\r\n",
        "from konlpy.tag import Okt\r\n",
        "\r\n",
        "\"\"\"'로','으로', '다', '했', '에', '의', '에서', '부터', '아', '하','고','도','것','그','으로','해진\r\n",
        "['을', '를', '이', '가', '은', '는', 'null','부터','에','에서','하','고','으로','로','의','만','하','고','도','았','었','다'\"\"\"\r\n",
        "\r\n",
        "def text_preprocessing(text_list):\r\n",
        "    \r\n",
        "    stopwords = [] #불용어 설정\r\n",
        "    \r\n",
        "    tokenizer = Mecab() #형태소 분석기 \r\n",
        "    token_list = [] \r\n",
        "    \r\n",
        "    for text in text_list:\r\n",
        "        txt = re.sub('[^가-힣]', ' ', text) #한글, 영어만 남기고 다른 글자 모두 제거\r\n",
        "        txt = re.sub('[가-힣\\s]+기자]','기자', txt) #기자 이름 제거\r\n",
        "        token = tokenizer.morphs(txt) #형태소 분석\r\n",
        "\r\n",
        "        #형태소 분석 결과 중 stopwords에 해당하지 않고, float type이 아닌 것만 수집\r\n",
        "        token = [t for t in token] \r\n",
        "        token_list.append(token)\r\n",
        "        \r\n",
        "    return token_list, tokenizer\r\n",
        "\r\n",
        "#형태소 분석기를 따로 저장한 이유는 후에 test 데이터 전처리를 진행할 때 이용해야 되기 때문입니다. \r\n",
        "train['new_article'], mecab = text_preprocessing(train['content'])\r\n",
        "#title도 동일하게 진행\r\n",
        "train['new_title'], title_mecab = text_preprocessing(train['title'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NtMOAeLoz3HN"
      },
      "source": [
        "# 결측치 제거\r\n",
        "train = train[train[\"new_article\"].apply(lambda x: False if len(x)==0 else True)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cyht3PbGT7SR"
      },
      "source": [
        "# Vectorization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F5O1nOzRK2AR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf24a13b-2d7f-47c7-af51-1df8c1470c81"
      },
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\r\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\r\n",
        "max_len = 40\r\n",
        "title_max_len = 15\r\n",
        "\r\n",
        "def text2sequence(train_text, max_len=100):\r\n",
        "    \r\n",
        "    tokenizer = Tokenizer()\r\n",
        "    tokenizer.fit_on_texts(train_text)\r\n",
        "    train_X_seq = tokenizer.texts_to_sequences(train_text)\r\n",
        "    vocab_size = len(tokenizer.word_index) + 1\r\n",
        "    print('vocab_size : ', vocab_size)\r\n",
        "    X_train = pad_sequences(train_X_seq, maxlen = max_len, truncating=\"post\") # 길이를 맞춰줌\r\n",
        "    return X_train, vocab_size, tokenizer\r\n",
        "\r\n",
        "train_y = train['info']\r\n",
        "train_X, vocab_size, vectorizer = text2sequence(train['new_article'], max_len = max_len)\r\n",
        "title_X, title_vocab_size, title_vectorizer = text2sequence(train['new_title'], max_len = title_max_len)\r\n",
        "\r\n",
        "print(train_X.shape, train_y.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "vocab_size :  33461\n",
            "vocab_size :  7926\n",
            "(118414, 40) (118414,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AVXYfzh6yyjP"
      },
      "source": [
        "# word2vec"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r1GnViYItOU_"
      },
      "source": [
        "import gensim\r\n",
        "from gensim.models.keyedvectors import KeyedVectors\r\n",
        "path = \"/gdrive/My Drive/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xd5zy8_5fwvT"
      },
      "source": [
        "# 한국어 word2vec model\r\n",
        "word2vec = gensim.models.Word2Vec.load(path+'ko.bin')\r\n",
        "embedding_size = 200"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EdSnbO4xWykD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9bd82d94-172b-4560-992b-9e1f6e06fe51"
      },
      "source": [
        "embedding_matrix = np.zeros((vocab_size, 200))\r\n",
        "title_embedding_matrix = np.zeros((title_vocab_size, 200))\r\n",
        "vocab = vectorizer.word_index\r\n",
        "title_vocab = title_vectorizer.word_index\r\n",
        "count = 0\r\n",
        "\r\n",
        "for idx, word in enumerate(vocab):\r\n",
        "    if word in word2vec:\r\n",
        "      embedding_vector = word2vec[word]\r\n",
        "      embedding_matrix[idx] = embedding_vector\r\n",
        "    else: # 임베딩 모델에 없는 것\r\n",
        "      #print(word, \"word2vec에 없는 단어입니다.\")\r\n",
        "      count += 1\r\n",
        "      pass\r\n",
        "\r\n",
        "\r\n",
        "for idx, word in enumerate(title_vocab):\r\n",
        "    if word in word2vec:\r\n",
        "      embedding_vector = word2vec[word]\r\n",
        "      title_embedding_matrix[idx] = embedding_vector\r\n",
        "    else: # 임베딩 모델에 없는 것\r\n",
        "      #print(word, \"word2vec에 없는 단어입니다.\")\r\n",
        "      count += 1\r\n",
        "      pass\r\n",
        "      "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: DeprecationWarning: Call to deprecated `__contains__` (Method will be removed in 4.0.0, use self.wv.__contains__() instead).\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:18: DeprecationWarning: Call to deprecated `__contains__` (Method will be removed in 4.0.0, use self.wv.__contains__() instead).\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:19: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8SDlbB8XIfHI"
      },
      "source": [
        "title_group = (train.groupby([\"title\"]).count())[\"n_id\"]\r\n",
        "train[\"new_ord\"]=train.apply(lambda x: x[\"ord\"]/title_group[x[\"title\"]], axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nR4QN16nJC0O"
      },
      "source": [
        "title_X = np.concatenate([title_X, train[\"new_ord\"].values.reshape(-1,1)], axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oi6C62j2JDAC"
      },
      "source": [
        "# 문장별로 train_test set 분리\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "\r\n",
        "#num_article = len(train[\"n_id\"].unique())\r\n",
        "#trainnp.random.randint(0,num_article,int(0.7*num_article))\r\n",
        "\r\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(train_X, train_y, random_state = 42, test_size = 0.3)\r\n",
        "X_title_train, X_title_valid, y_title_train, y_title_valid = train_test_split(title_X, train_y, random_state=42, test_size=0.3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Byo4DlwFIyob"
      },
      "source": [
        "# EDA기반으로 만든 feature 예측변수로 추가\r\n",
        "from keras import regularizers\r\n",
        "\r\n",
        "def title_LSTM2(title_vocab_size, embedding_size = 200, title_max_len=100):\r\n",
        "  input1 = keras.layers.Input(shape = [title_max_len,]) #문장 단어 input\r\n",
        "  input2 = keras.layers.Input(shape = [1,]) # EDA기반 feature input\r\n",
        "\r\n",
        "  # LSTM\r\n",
        "  embedding = keras.layers.Embedding(title_vocab_size, embedding_size, weights = [title_embedding_matrix], input_length = title_max_len)(input1) # 임베딩 가중치 적용\r\n",
        "  dropout1 = keras.layers.SpatialDropout1D(0.1)(embedding)\r\n",
        "  lstm1 = keras.layers.LSTM(32, return_sequences = True)(dropout1)\r\n",
        "  lstm2 = keras.layers.LSTM(32)(lstm1)\r\n",
        "  dropout2 = keras.layers.Dropout(0.3)(lstm2)\r\n",
        "  #lstm_output = keras.layers.Dense(16, activation = \"selu\")(dropout2)\r\n",
        "\r\n",
        "  # MLP\r\n",
        "  concat = keras.layers.concatenate([dropout2,input2])\r\n",
        "  hidden = keras.layers.Dense(16, activation = \"selu\")(concat)\r\n",
        "  output = keras.layers.Dense(1, activation = \"sigmoid\")(hidden)\r\n",
        "\r\n",
        "  model = keras.Model(inputs = [input1, input2], outputs = [output])\r\n",
        "\r\n",
        "  model.compile(optimizer=keras.optimizers.Adam(lr=learning_rate), loss=\"binary_crossentropy\", metrics = \"accuracy\")\r\n",
        "  model.summary()\r\n",
        "  return model\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "51yjivz3Il9o",
        "outputId": "abe89ab0-6376-4f19-f8df-7f0774b9484f"
      },
      "source": [
        "# 훈련 시\r\n",
        "tf.random.set_seed(42)\r\n",
        "\r\n",
        "\r\n",
        "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"hyerim_add_feature_best_model2.h5\",\r\n",
        "                                               save_best_only = True)\r\n",
        "\r\n",
        "# 하이퍼파라미터\r\n",
        "max_epoch = 50\r\n",
        "batch_size = 100\r\n",
        "learning_rate = 0.001\r\n",
        "\r\n",
        "model = title_LSTM2(title_vocab_size, title_max_len = title_max_len)\r\n",
        "history = model.fit(x=[X_title_train[:,:title_max_len],X_title_train[:,-1:]], y=y_train,epochs=max_epoch,\r\n",
        "                batch_size = batch_size,  validation_data = ((X_title_valid[:,:title_max_len],X_title_valid[:,-1:]),y_valid), validation_batch_size = batch_size,\r\n",
        "                 callbacks = [checkpoint_cb])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_8\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_21 (InputLayer)           [(None, 15)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_22 (Embedding)        (None, 15, 200)      1585200     input_21[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "spatial_dropout1d_20 (SpatialDr (None, 15, 200)      0           embedding_22[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "lstm_40 (LSTM)                  (None, 15, 32)       29824       spatial_dropout1d_20[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "lstm_41 (LSTM)                  (None, 32)           8320        lstm_40[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_20 (Dropout)            (None, 32)           0           lstm_41[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "input_22 (InputLayer)           [(None, 1)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_8 (Concatenate)     (None, 33)           0           dropout_20[0][0]                 \n",
            "                                                                 input_22[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_40 (Dense)                (None, 16)           544         concatenate_8[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense_41 (Dense)                (None, 1)            17          dense_40[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 1,623,905\n",
            "Trainable params: 1,623,905\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/50\n",
            "829/829 [==============================] - 41s 46ms/step - loss: 0.5969 - accuracy: 0.6737 - val_loss: 0.4971 - val_accuracy: 0.7487\n",
            "Epoch 2/50\n",
            "829/829 [==============================] - 37s 45ms/step - loss: 0.4933 - accuracy: 0.7525 - val_loss: 0.4846 - val_accuracy: 0.7499\n",
            "Epoch 3/50\n",
            "829/829 [==============================] - 37s 44ms/step - loss: 0.4761 - accuracy: 0.7588 - val_loss: 0.4777 - val_accuracy: 0.7542\n",
            "Epoch 4/50\n",
            "829/829 [==============================] - 37s 44ms/step - loss: 0.4674 - accuracy: 0.7616 - val_loss: 0.4767 - val_accuracy: 0.7511\n",
            "Epoch 5/50\n",
            "829/829 [==============================] - 38s 46ms/step - loss: 0.4612 - accuracy: 0.7624 - val_loss: 0.4739 - val_accuracy: 0.7582\n",
            "Epoch 6/50\n",
            "829/829 [==============================] - 37s 44ms/step - loss: 0.4544 - accuracy: 0.7669 - val_loss: 0.4706 - val_accuracy: 0.7556\n",
            "Epoch 7/50\n",
            "829/829 [==============================] - 37s 44ms/step - loss: 0.4512 - accuracy: 0.7658 - val_loss: 0.4671 - val_accuracy: 0.7595\n",
            "Epoch 8/50\n",
            "829/829 [==============================] - 37s 45ms/step - loss: 0.4453 - accuracy: 0.7729 - val_loss: 0.4670 - val_accuracy: 0.7636\n",
            "Epoch 9/50\n",
            "829/829 [==============================] - 37s 44ms/step - loss: 0.4476 - accuracy: 0.7703 - val_loss: 0.4631 - val_accuracy: 0.7655\n",
            "Epoch 10/50\n",
            "829/829 [==============================] - 39s 48ms/step - loss: 0.4371 - accuracy: 0.7744 - val_loss: 0.4570 - val_accuracy: 0.7713\n",
            "Epoch 11/50\n",
            "829/829 [==============================] - 37s 44ms/step - loss: 0.4331 - accuracy: 0.7794 - val_loss: 0.4551 - val_accuracy: 0.7755\n",
            "Epoch 12/50\n",
            "829/829 [==============================] - 37s 45ms/step - loss: 0.4279 - accuracy: 0.7845 - val_loss: 0.4497 - val_accuracy: 0.7724\n",
            "Epoch 13/50\n",
            "829/829 [==============================] - 38s 46ms/step - loss: 0.4224 - accuracy: 0.7869 - val_loss: 0.4454 - val_accuracy: 0.7760\n",
            "Epoch 14/50\n",
            "829/829 [==============================] - 37s 45ms/step - loss: 0.4125 - accuracy: 0.7945 - val_loss: 0.4417 - val_accuracy: 0.7887\n",
            "Epoch 15/50\n",
            "829/829 [==============================] - 37s 45ms/step - loss: 0.4065 - accuracy: 0.7963 - val_loss: 0.4426 - val_accuracy: 0.7845\n",
            "Epoch 16/50\n",
            "829/829 [==============================] - 37s 44ms/step - loss: 0.4021 - accuracy: 0.7996 - val_loss: 0.4358 - val_accuracy: 0.7924\n",
            "Epoch 17/50\n",
            "829/829 [==============================] - 37s 44ms/step - loss: 0.3984 - accuracy: 0.8032 - val_loss: 0.4338 - val_accuracy: 0.7981\n",
            "Epoch 18/50\n",
            "829/829 [==============================] - 37s 45ms/step - loss: 0.3916 - accuracy: 0.8066 - val_loss: 0.4337 - val_accuracy: 0.7949\n",
            "Epoch 19/50\n",
            "829/829 [==============================] - 37s 44ms/step - loss: 0.3857 - accuracy: 0.8122 - val_loss: 0.4299 - val_accuracy: 0.8061\n",
            "Epoch 20/50\n",
            "829/829 [==============================] - 37s 45ms/step - loss: 0.3775 - accuracy: 0.8179 - val_loss: 0.4223 - val_accuracy: 0.8039\n",
            "Epoch 21/50\n",
            "829/829 [==============================] - 37s 45ms/step - loss: 0.3766 - accuracy: 0.8175 - val_loss: 0.4256 - val_accuracy: 0.8112\n",
            "Epoch 22/50\n",
            "829/829 [==============================] - 38s 45ms/step - loss: 0.3640 - accuracy: 0.8283 - val_loss: 0.4152 - val_accuracy: 0.8186\n",
            "Epoch 23/50\n",
            "829/829 [==============================] - 37s 45ms/step - loss: 0.3574 - accuracy: 0.8366 - val_loss: 0.4093 - val_accuracy: 0.8253\n",
            "Epoch 24/50\n",
            "829/829 [==============================] - 37s 45ms/step - loss: 0.3520 - accuracy: 0.8397 - val_loss: 0.4053 - val_accuracy: 0.8335\n",
            "Epoch 25/50\n",
            "829/829 [==============================] - 37s 45ms/step - loss: 0.3465 - accuracy: 0.8462 - val_loss: 0.4005 - val_accuracy: 0.8348\n",
            "Epoch 26/50\n",
            "829/829 [==============================] - 40s 48ms/step - loss: 0.3374 - accuracy: 0.8522 - val_loss: 0.4004 - val_accuracy: 0.8392\n",
            "Epoch 27/50\n",
            "829/829 [==============================] - 37s 45ms/step - loss: 0.3288 - accuracy: 0.8597 - val_loss: 0.3940 - val_accuracy: 0.8461\n",
            "Epoch 28/50\n",
            "829/829 [==============================] - 37s 45ms/step - loss: 0.3236 - accuracy: 0.8657 - val_loss: 0.3889 - val_accuracy: 0.8516\n",
            "Epoch 29/50\n",
            "829/829 [==============================] - 37s 45ms/step - loss: 0.3162 - accuracy: 0.8718 - val_loss: 0.3824 - val_accuracy: 0.8630\n",
            "Epoch 30/50\n",
            "829/829 [==============================] - 38s 45ms/step - loss: 0.3074 - accuracy: 0.8789 - val_loss: 0.3793 - val_accuracy: 0.8636\n",
            "Epoch 31/50\n",
            "829/829 [==============================] - 38s 46ms/step - loss: 0.3008 - accuracy: 0.8838 - val_loss: 0.3762 - val_accuracy: 0.8680\n",
            "Epoch 32/50\n",
            "829/829 [==============================] - 38s 46ms/step - loss: 0.2932 - accuracy: 0.8912 - val_loss: 0.3692 - val_accuracy: 0.8771\n",
            "Epoch 33/50\n",
            "829/829 [==============================] - 37s 45ms/step - loss: 0.2893 - accuracy: 0.8962 - val_loss: 0.3688 - val_accuracy: 0.8746\n",
            "Epoch 34/50\n",
            "829/829 [==============================] - 37s 45ms/step - loss: 0.2829 - accuracy: 0.8994 - val_loss: 0.3632 - val_accuracy: 0.8846\n",
            "Epoch 35/50\n",
            "829/829 [==============================] - 37s 45ms/step - loss: 0.2741 - accuracy: 0.9053 - val_loss: 0.3581 - val_accuracy: 0.8940\n",
            "Epoch 36/50\n",
            "829/829 [==============================] - 37s 45ms/step - loss: 0.2690 - accuracy: 0.9106 - val_loss: 0.3644 - val_accuracy: 0.8933\n",
            "Epoch 37/50\n",
            "829/829 [==============================] - 38s 45ms/step - loss: 0.2632 - accuracy: 0.9118 - val_loss: 0.3527 - val_accuracy: 0.8987\n",
            "Epoch 38/50\n",
            "829/829 [==============================] - 37s 45ms/step - loss: 0.2590 - accuracy: 0.9157 - val_loss: 0.3524 - val_accuracy: 0.8904\n",
            "Epoch 39/50\n",
            "829/829 [==============================] - 38s 46ms/step - loss: 0.2503 - accuracy: 0.9187 - val_loss: 0.3466 - val_accuracy: 0.9062\n",
            "Epoch 40/50\n",
            "829/829 [==============================] - 37s 45ms/step - loss: 0.2439 - accuracy: 0.9211 - val_loss: 0.3597 - val_accuracy: 0.8886\n",
            "Epoch 41/50\n",
            "829/829 [==============================] - 37s 45ms/step - loss: 0.2444 - accuracy: 0.9243 - val_loss: 0.3500 - val_accuracy: 0.9067\n",
            "Epoch 42/50\n",
            "829/829 [==============================] - 38s 46ms/step - loss: 0.2380 - accuracy: 0.9251 - val_loss: 0.3407 - val_accuracy: 0.9119\n",
            "Epoch 43/50\n",
            "829/829 [==============================] - 38s 46ms/step - loss: 0.2307 - accuracy: 0.9296 - val_loss: 0.3421 - val_accuracy: 0.9095\n",
            "Epoch 44/50\n",
            "829/829 [==============================] - 37s 45ms/step - loss: 0.2295 - accuracy: 0.9312 - val_loss: 0.3402 - val_accuracy: 0.9124\n",
            "Epoch 45/50\n",
            "829/829 [==============================] - 37s 45ms/step - loss: 0.2215 - accuracy: 0.9351 - val_loss: 0.3372 - val_accuracy: 0.9091\n",
            "Epoch 46/50\n",
            "829/829 [==============================] - 38s 45ms/step - loss: 0.2195 - accuracy: 0.9346 - val_loss: 0.3410 - val_accuracy: 0.9098\n",
            "Epoch 47/50\n",
            "829/829 [==============================] - 37s 45ms/step - loss: 0.2158 - accuracy: 0.9348 - val_loss: 0.3363 - val_accuracy: 0.9058\n",
            "Epoch 48/50\n",
            "829/829 [==============================] - 38s 46ms/step - loss: 0.2134 - accuracy: 0.9361 - val_loss: 0.3403 - val_accuracy: 0.9133\n",
            "Epoch 49/50\n",
            "829/829 [==============================] - 37s 45ms/step - loss: 0.2087 - accuracy: 0.9395 - val_loss: 0.3351 - val_accuracy: 0.9192\n",
            "Epoch 50/50\n",
            "829/829 [==============================] - 37s 45ms/step - loss: 0.2047 - accuracy: 0.9396 - val_loss: 0.3347 - val_accuracy: 0.9120\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 765
        },
        "id": "ZDJ1nHiva_xj",
        "outputId": "e5f26ee2-8186-4349-9e1e-c63f36d39d1b"
      },
      "source": [
        "history = model.fit(x=[X_title_train[:,:title_max_len],X_title_train[:,-1:]], y=y_train,epochs=30,\r\n",
        "                batch_size = batch_size,  validation_data = ((X_title_valid[:,:title_max_len],X_title_valid[:,-1:]),y_valid), validation_batch_size = batch_size,\r\n",
        "                 callbacks = [checkpoint_cb])\r\n",
        "# epoch : 52"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "829/829 [==============================] - 37s 45ms/step - loss: 0.2048 - accuracy: 0.9388 - val_loss: 0.3415 - val_accuracy: 0.9168\n",
            "Epoch 2/30\n",
            "829/829 [==============================] - 38s 45ms/step - loss: 0.2012 - accuracy: 0.9397 - val_loss: 0.3273 - val_accuracy: 0.9211\n",
            "Epoch 3/30\n",
            "829/829 [==============================] - 37s 45ms/step - loss: 0.1989 - accuracy: 0.9405 - val_loss: 0.3356 - val_accuracy: 0.9168\n",
            "Epoch 4/30\n",
            "829/829 [==============================] - 37s 45ms/step - loss: 0.1955 - accuracy: 0.9419 - val_loss: 0.3322 - val_accuracy: 0.9170\n",
            "Epoch 5/30\n",
            "829/829 [==============================] - 37s 45ms/step - loss: 0.1943 - accuracy: 0.9418 - val_loss: 0.3335 - val_accuracy: 0.9177\n",
            "Epoch 6/30\n",
            "829/829 [==============================] - 37s 45ms/step - loss: 0.1911 - accuracy: 0.9425 - val_loss: 0.3307 - val_accuracy: 0.9252\n",
            "Epoch 7/30\n",
            "829/829 [==============================] - 37s 45ms/step - loss: 0.1894 - accuracy: 0.9428 - val_loss: 0.3304 - val_accuracy: 0.9239\n",
            "Epoch 8/30\n",
            "829/829 [==============================] - 39s 47ms/step - loss: 0.1874 - accuracy: 0.9425 - val_loss: 0.3285 - val_accuracy: 0.9213\n",
            "Epoch 9/30\n",
            "829/829 [==============================] - 37s 45ms/step - loss: 0.1846 - accuracy: 0.9446 - val_loss: 0.3393 - val_accuracy: 0.9203\n",
            "Epoch 10/30\n",
            "155/829 [====>.........................] - ETA: 28s - loss: 0.1822 - accuracy: 0.9461"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-139-2b0329607a06>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m history = model.fit(x=[X_title_train[:,:title_max_len],X_title_train[:,-1:]], y=y_train,epochs=30,\n\u001b[1;32m      2\u001b[0m                 \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_title_valid\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtitle_max_len\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_title_valid\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_batch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m                  callbacks = [checkpoint_cb])\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a2MCCbu1MRmY"
      },
      "source": [
        "best_model = keras.models.load_model(\"hyerim_add_feature_best_model2.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ptQTuhZbMaQU"
      },
      "source": [
        "predicted = best_model.predict((title_X[:,:title_max_len],title_X[:,-1:]))\r\n",
        "train[\"title_predicted\"]=predicted\r\n",
        "train.to_csv(\"try_title_data.csv\",index=False, encoding=\"utf-8-sig\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VtsZwZ-7hXKb"
      },
      "source": [
        "# 최종 훈련"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G60Y-PqkhaRB",
        "outputId": "ba8004df-4c96-4175-cbaa-3e1ba51e5c9b"
      },
      "source": [
        "# 훈련 시\r\n",
        "tf.random.set_seed(42)\r\n",
        "\r\n",
        "\r\n",
        "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"title_model.h5\",\r\n",
        "                                               save_best_only = True)\r\n",
        "\r\n",
        "# 하이퍼파라미터\r\n",
        "max_epoch = 52\r\n",
        "batch_size = 100\r\n",
        "learning_rate = 0.001\r\n",
        "\r\n",
        "model = title_LSTM2(title_vocab_size, title_max_len = title_max_len)\r\n",
        "history = model.fit(x=[title_X[:,:title_max_len],title_X[:,-1:]], y=train_y, epochs=max_epoch,\r\n",
        "                batch_size = batch_size, callbacks = [checkpoint_cb])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_11\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_27 (InputLayer)           [(None, 15)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_25 (Embedding)        (None, 15, 200)      1585200     input_27[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "spatial_dropout1d_23 (SpatialDr (None, 15, 200)      0           embedding_25[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "lstm_46 (LSTM)                  (None, 15, 32)       29824       spatial_dropout1d_23[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "lstm_47 (LSTM)                  (None, 32)           8320        lstm_46[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_23 (Dropout)            (None, 32)           0           lstm_47[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "input_28 (InputLayer)           [(None, 1)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_11 (Concatenate)    (None, 33)           0           dropout_23[0][0]                 \n",
            "                                                                 input_28[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_46 (Dense)                (None, 16)           544         concatenate_11[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dense_47 (Dense)                (None, 1)            17          dense_46[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 1,623,905\n",
            "Trainable params: 1,623,905\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/52\n",
            "1185/1185 [==============================] - 55s 43ms/step - loss: 0.5800 - accuracy: 0.6916\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "Epoch 2/52\n",
            "1185/1185 [==============================] - 51s 43ms/step - loss: 0.4869 - accuracy: 0.7532\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "Epoch 3/52\n",
            "1185/1185 [==============================] - 51s 43ms/step - loss: 0.4729 - accuracy: 0.7579\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "Epoch 4/52\n",
            "1185/1185 [==============================] - 51s 43ms/step - loss: 0.4615 - accuracy: 0.7629\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "Epoch 5/52\n",
            "1185/1185 [==============================] - 51s 43ms/step - loss: 0.4548 - accuracy: 0.7657\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "Epoch 6/52\n",
            "1185/1185 [==============================] - 51s 43ms/step - loss: 0.4535 - accuracy: 0.7650\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "Epoch 7/52\n",
            "1185/1185 [==============================] - 52s 44ms/step - loss: 0.4458 - accuracy: 0.7724\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "Epoch 8/52\n",
            "1185/1185 [==============================] - 51s 43ms/step - loss: 0.4412 - accuracy: 0.7734\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "Epoch 9/52\n",
            "1185/1185 [==============================] - 51s 43ms/step - loss: 0.4354 - accuracy: 0.7774\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "Epoch 10/52\n",
            "1185/1185 [==============================] - 54s 46ms/step - loss: 0.4270 - accuracy: 0.7837\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "Epoch 11/52\n",
            "1185/1185 [==============================] - 51s 43ms/step - loss: 0.4245 - accuracy: 0.7851\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "Epoch 12/52\n",
            "1185/1185 [==============================] - 51s 43ms/step - loss: 0.4177 - accuracy: 0.7898\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "Epoch 13/52\n",
            "1185/1185 [==============================] - 51s 43ms/step - loss: 0.4129 - accuracy: 0.7925\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "Epoch 14/52\n",
            "1185/1185 [==============================] - 51s 43ms/step - loss: 0.4095 - accuracy: 0.7963\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "Epoch 15/52\n",
            "1185/1185 [==============================] - 51s 43ms/step - loss: 0.4052 - accuracy: 0.7979\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "Epoch 16/52\n",
            "1185/1185 [==============================] - 52s 43ms/step - loss: 0.4025 - accuracy: 0.8003\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "Epoch 17/52\n",
            "1185/1185 [==============================] - 51s 43ms/step - loss: 0.3961 - accuracy: 0.8047\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "Epoch 18/52\n",
            "1185/1185 [==============================] - 51s 43ms/step - loss: 0.3901 - accuracy: 0.8084\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "Epoch 19/52\n",
            "1185/1185 [==============================] - 51s 43ms/step - loss: 0.3840 - accuracy: 0.8163\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "Epoch 20/52\n",
            "1185/1185 [==============================] - 51s 43ms/step - loss: 0.3778 - accuracy: 0.8209\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "Epoch 21/52\n",
            "1185/1185 [==============================] - 51s 43ms/step - loss: 0.3710 - accuracy: 0.8257\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "Epoch 22/52\n",
            "1185/1185 [==============================] - 54s 45ms/step - loss: 0.3653 - accuracy: 0.8336\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "Epoch 23/52\n",
            "1185/1185 [==============================] - 52s 44ms/step - loss: 0.3561 - accuracy: 0.8405\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "Epoch 24/52\n",
            "1185/1185 [==============================] - 51s 43ms/step - loss: 0.3463 - accuracy: 0.8493\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "Epoch 25/52\n",
            "1185/1185 [==============================] - 52s 44ms/step - loss: 0.3406 - accuracy: 0.8563\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "Epoch 26/52\n",
            "1185/1185 [==============================] - 51s 43ms/step - loss: 0.3324 - accuracy: 0.8661\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "Epoch 27/52\n",
            "1185/1185 [==============================] - 51s 43ms/step - loss: 0.3237 - accuracy: 0.8732\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "Epoch 28/52\n",
            "1185/1185 [==============================] - 51s 43ms/step - loss: 0.3175 - accuracy: 0.8802\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "Epoch 29/52\n",
            "1185/1185 [==============================] - 52s 44ms/step - loss: 0.3075 - accuracy: 0.8892\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "Epoch 30/52\n",
            "1185/1185 [==============================] - 51s 43ms/step - loss: 0.3030 - accuracy: 0.8928\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "Epoch 31/52\n",
            "1185/1185 [==============================] - 51s 43ms/step - loss: 0.2997 - accuracy: 0.8971\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "Epoch 32/52\n",
            "1185/1185 [==============================] - 51s 43ms/step - loss: 0.2913 - accuracy: 0.9025\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "Epoch 33/52\n",
            "1185/1185 [==============================] - 54s 45ms/step - loss: 0.2868 - accuracy: 0.9057\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "Epoch 34/52\n",
            "1185/1185 [==============================] - 52s 44ms/step - loss: 0.2802 - accuracy: 0.9086\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "Epoch 35/52\n",
            "1185/1185 [==============================] - 53s 45ms/step - loss: 0.2750 - accuracy: 0.9117\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "Epoch 36/52\n",
            "1185/1185 [==============================] - 52s 44ms/step - loss: 0.2699 - accuracy: 0.9123\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "Epoch 37/52\n",
            "1185/1185 [==============================] - 52s 44ms/step - loss: 0.2672 - accuracy: 0.9184\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "Epoch 38/52\n",
            "1185/1185 [==============================] - 52s 44ms/step - loss: 0.2636 - accuracy: 0.9194\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "Epoch 39/52\n",
            "1185/1185 [==============================] - 51s 43ms/step - loss: 0.2582 - accuracy: 0.9221\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "Epoch 40/52\n",
            "1185/1185 [==============================] - 51s 43ms/step - loss: 0.2568 - accuracy: 0.9223\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "Epoch 41/52\n",
            "1185/1185 [==============================] - 52s 44ms/step - loss: 0.2529 - accuracy: 0.9230\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "Epoch 42/52\n",
            "1185/1185 [==============================] - 52s 44ms/step - loss: 0.2456 - accuracy: 0.9261\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "Epoch 43/52\n",
            "1185/1185 [==============================] - 51s 43ms/step - loss: 0.2426 - accuracy: 0.9255\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "Epoch 44/52\n",
            "1185/1185 [==============================] - 51s 43ms/step - loss: 0.2420 - accuracy: 0.9276\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "Epoch 45/52\n",
            "1185/1185 [==============================] - 54s 45ms/step - loss: 0.2389 - accuracy: 0.9278\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "Epoch 46/52\n",
            "1185/1185 [==============================] - 51s 43ms/step - loss: 0.2369 - accuracy: 0.9290\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "Epoch 47/52\n",
            "1185/1185 [==============================] - 52s 44ms/step - loss: 0.2339 - accuracy: 0.9284\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "Epoch 48/52\n",
            "1185/1185 [==============================] - 51s 43ms/step - loss: 0.2300 - accuracy: 0.9309\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "Epoch 49/52\n",
            "1185/1185 [==============================] - 51s 43ms/step - loss: 0.2265 - accuracy: 0.9301\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "Epoch 50/52\n",
            "1185/1185 [==============================] - 51s 43ms/step - loss: 0.2262 - accuracy: 0.9308\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "Epoch 51/52\n",
            "1185/1185 [==============================] - 51s 43ms/step - loss: 0.2203 - accuracy: 0.9329\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "Epoch 52/52\n",
            "1185/1185 [==============================] - 51s 43ms/step - loss: 0.2189 - accuracy: 0.9332\n",
            "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yvEx3-XYhkZp"
      },
      "source": [
        "model.save(\"title_model.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}