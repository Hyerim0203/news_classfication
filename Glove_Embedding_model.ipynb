{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Word2Vec_Embedding_model",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "FwAQw1o2Av2C"
      },
      "source": [
        "# konlpy Mecab 사용하기\r\n",
        "\r\n",
        "!set -x \\\r\n",
        "&& pip install konlpy \\\r\n",
        "&& curl -s https://raw.githubusercontent.com/konlpy/konlpy/master/scripts/mecab.sh | bash -x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V37NJICIXWXk"
      },
      "source": [
        "!pip install glove_python"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RmU0g2Oh_cL6",
        "outputId": "90b53e67-33ab-4bb2-f24b-5d23be2c7f31"
      },
      "source": [
        "# 내 드라이브에 대한 주소\r\n",
        "from google.colab import drive\r\n",
        "drive.mount('/gdrive', force_remount=True)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E9CfaH0yAYcL"
      },
      "source": [
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "import tensorflow as tf\r\n",
        "from tensorflow import keras\r\n",
        "import seaborn as sns\r\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tR74GZMCBBuz"
      },
      "source": [
        "path = \"/gdrive/My Drive/dacon_news\"\r\n",
        "\r\n",
        "train = pd.read_csv(path + \"/data/news_train.csv\")\r\n",
        "test = pd.read_csv(path + \"/data/news_test.csv\")"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tX7VJJdS6NiF"
      },
      "source": [
        "# 학습시킬 말뭉치 준비"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Piur47l5A1TI"
      },
      "source": [
        "from konlpy.tag import Mecab\r\n",
        "import re\r\n",
        "from konlpy.tag import Okt\r\n",
        "\r\n",
        "def text_preprocessing(text_list):\r\n",
        "    \r\n",
        "    stopwords = ['이']\r\n",
        "    tokenizer = Mecab() #형태소 분석기\r\n",
        "\r\n",
        "    token_list = [] \r\n",
        "    \r\n",
        "    for text in text_list:\r\n",
        "        txt = re.sub(\"[a-zA-Z0-9]\", ' ', text) #영문 제거\r\n",
        "        txt = re.sub('[가-힣]+\\s기자','기자', txt) #기자 이름 제거\r\n",
        "        token = tokenizer.morphs(txt) #형태소 분석\r\n",
        "\r\n",
        "        token = [t for t in token if t not in stopwords] \r\n",
        "        token_list.append(token)\r\n",
        "        \r\n",
        "    return token_list, tokenizer\r\n",
        "\r\n",
        "#형태소 분석기를 따로 저장한 이유는 후에 test 데이터 전처리를 진행할 때 이용해야 되기 때문입니다.\r\n",
        "embedding_train = pd.concat([train[\"content\"],test[\"content\"]],axis=0)\r\n",
        "embedding_train, okt = text_preprocessing(embedding_train)"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ehHgLfhIMZ0U"
      },
      "source": [
        "# Glove\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g-5XDYvB6Kuh",
        "outputId": "fb3d4067-167e-4680-a466-da303112adab"
      },
      "source": [
        "from glove import Corpus, Glove\r\n",
        "\r\n",
        "corpus = Corpus() \r\n",
        "corpus.fit(embedding_train, window=10)\r\n",
        "# 훈련 데이터로부터 GloVe에서 사용할 동시 등장 행렬 생성\r\n",
        "\r\n",
        "glove = Glove(no_components=300, learning_rate=0.05)\r\n",
        "glove.fit(corpus.matrix, epochs=5, no_threads=4, verbose=True)\r\n",
        "glove.add_dictionary(corpus.dictionary)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Performing 5 training epochs with 4 threads\n",
            "Epoch 0\n",
            "Epoch 1\n",
            "Epoch 2\n",
            "Epoch 3\n",
            "Epoch 4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i2n5mti3wnZ0"
      },
      "source": [
        "# Word2Vec"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hp2dMIMsILWJ"
      },
      "source": [
        "from gensim.models.word2vec import Word2Vec"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PuwkKJQBH6RO"
      },
      "source": [
        "embedding_model = Word2Vec(embedding_train,         # 리스트 형태의 데이터\r\n",
        "                 sg=1,          # 0: CBOW, 1: Skip-gram\r\n",
        "                 size = 300,      # 벡터 크기(300)\r\n",
        "                 window = 10,     # 고려할 앞뒤 폭(앞뒤 10단어)\r\n",
        "                 min_count = 30,  # 사용할 단어의 최소 빈도(30회 이하 단어 무시)\r\n",
        "                 workers = -1,    # 동시에 처리할 작업 수(코어 수와 비슷하게 설정)\r\n",
        "                 iter = 30)    "
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NNdnzbXXJqtV"
      },
      "source": [
        "embedding_model.save(\"embedding_300_10_30_iter_30.model\")"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LH6TVCIwM-4U",
        "outputId": "09868bde-e939-4f88-df9c-85f74d874df0"
      },
      "source": [
        "embedding_model.most_similar(\"]\")"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('하원', 0.19800397753715515),\n",
              " ('경매', 0.1971077024936676),\n",
              " ('현충원', 0.19422751665115356),\n",
              " ('연구자', 0.18848800659179688),\n",
              " ('벌어졌', 0.18307097256183624),\n",
              " ('그대로', 0.18146532773971558),\n",
              " ('구역', 0.17465075850486755),\n",
              " ('팬', 0.1736888587474823),\n",
              " ('사위', 0.17347624897956848),\n",
              " ('이끌', 0.17254045605659485)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GcjyjF9aNAv9",
        "outputId": "328340e8-08dc-4e64-e441-40f5393ca30c"
      },
      "source": [
        "embedding_model.most_similar('카톡')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('방사광', 0.2288285493850708),\n",
              " ('폰', 0.21296778321266174),\n",
              " ('대원', 0.210852712392807),\n",
              " ('노리', 0.20738786458969116),\n",
              " ('분양', 0.20020851492881775),\n",
              " ('봉', 0.19835519790649414),\n",
              " ('형사', 0.19768759608268738),\n",
              " ('마켓', 0.19744479656219482),\n",
              " ('기원', 0.19487667083740234),\n",
              " ('푸르', 0.19428278505802155)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IDyQP1T296Py"
      },
      "source": [
        "embedding_300_10_30_all : 영문, 숫자, '이', 기자 이름 제거  \r\n",
        "embedding_300_10_30_final : 영문, 숫자만 제거  \r\n",
        "embedding_300_10_30_all_new : 영문, 숫자만 제거, 기자 이름 제거 X"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lwreUUnxyP0U"
      },
      "source": [
        "class Full_Lag_RNN(keras.Model):\r\n",
        "  def __init__(self,units = 30, max_len = 50, activation = \"relu\", **kwargs):\r\n",
        "    super().__init__(**kwargs)\r\n",
        "    self.max_len = max_len\r\n",
        "    self.hidden1 = keras.layers.SimpleRNN(units, activation = \"selu\")\r\n",
        "    self.hidden2 = keras.layers.SimpleRNN(units, activation = \"selu\")\r\n",
        "\r\n",
        "    self.output = keras.layers.Dense(1, activatino = \"signoid\")\r\n",
        "\r\n",
        "  def call(self, inputs):\r\n",
        "    input_ = inputs\r\n",
        "    hidden1 = self.hidden1(input_)\r\n",
        "    hidden2 = self.hidden2(hidden1)\r\n",
        "    output = self.output(hidden2)\r\n",
        "    return output"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}