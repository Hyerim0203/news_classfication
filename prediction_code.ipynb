{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_3LcHWdoaKXK"
   },
   "source": [
    "# **팀명 : 678**\n",
    "# **Prediction Code**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QsDtXDrsFFIf"
   },
   "source": [
    "# Library 설치 및 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FwAQw1o2Av2C"
   },
   "outputs": [],
   "source": [
    "# Library 설치 및 데이터 불러오기\n",
    "\n",
    "# konlpy Mecab 설치\n",
    "!set -x \\\n",
    "&& pip install konlpy \\\n",
    "&& curl -s https://raw.githubusercontent.com/konlpy/konlpy/master/scripts/mecab.sh | bash -x\n",
    "\n",
    "# 데이터 불러오기\n",
    "import pandas as pd\n",
    "path = \"/content/678/\"\n",
    "test = pd.read_csv(path+\"1.Data/news_test.csv\",encoding = 'utf-8-sig')\n",
    "submission = pd.read_csv(path+\"1.Data/sample_submission.csv\",encoding = 'utf-8-sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TE-LaFwp7xFl"
   },
   "source": [
    "# 시간 측정 시작"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j_l6IJrF7wpa"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "start = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dXa50Q0aFm9n"
   },
   "source": [
    "# Library 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xH9XAIwVNM6i"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from konlpy.tag import Mecab\n",
    "import re\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uUWEPSDYKMsS"
   },
   "source": [
    "# Tokenizer, Model 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zMjY6B7nKQCe"
   },
   "outputs": [],
   "source": [
    "vectorizer = joblib.load(path+\"3.Tokenizer/vectorizer.sav\") # tokenizer 불러오기\n",
    "lstm_model = keras.models.load_model(path+\"5.Model/lstm_model.h5\") # lstm 모델 불러오기\n",
    "lgbm_model = joblib.load(path+'5.Model/lgbm_model.pkl') # lgbm 모델 불러오기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uIEvmB_0HWCu"
   },
   "source": [
    "# 변수추가 + 형태소 분석 + 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bcwUcZBRVEvd"
   },
   "outputs": [],
   "source": [
    "# feature 추가\n",
    "\n",
    "# content 맨앞이 \"[\" / \"(\" / \"제목\" 이면 info 1\n",
    "test[\"content_startswith_[\"]=test.content.apply(lambda x : str(x).startswith(\"[\" ) or str(x).startswith(\"(\") or str(x).startswith(\"제목\"))+0\n",
    "\n",
    "# title에 해당 단어들이 포함되면 info 1\n",
    "title_noise = ['적중 100%', '글로벌 주요 뉴스', '[전문가 의견]', \n",
    "               '[포커스]', '※','■', '★',' TOP', 'BEST',\n",
    "               '전문가의 눈', '전문가선정', '전문가의견','】','후속주도 감사합니다',\n",
    "               '전문가추천', '주요이슈']\n",
    "def title_choose(x):\n",
    "  if (\"종목\" in x[-6:]) or (\"관련주\" in x[-5:]):\n",
    "    return 1\n",
    "  for noise in title_noise:\n",
    "    if noise in x.upper():\n",
    "        return 1\n",
    "  return 0\n",
    "test[\"info1_title\"]=test['title'].apply(title_choose)\n",
    "\n",
    "# content에 해당 단어들이 포함되면 info 1\n",
    "content_noise = ['00%', '긴급공개', '긴급 공개','임상3상','# ','대장株','대장주','카톡','원\"만','TOP','BEST']\n",
    "def content_choose(x):\n",
    "  if (x=='관련기사') or (x==\"관련 테마분석\") or (x==\"코스피\") or (x==\"코스닥\"):\n",
    "    return 1\n",
    "  for noise in content_noise:\n",
    "    if noise in x.upper():\n",
    "        return 1\n",
    "  return 0\n",
    "test[\"info1_content\"]=test[\"content\"].apply(content_choose)\n",
    "\n",
    "# order을 이용한 feature\n",
    "title_group = (test.groupby([\"title\"]).count())[\"n_id\"]\n",
    "test[\"new_ord\"]=test.apply(lambda x: x[\"ord\"]/title_group[x[\"title\"]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s9C_faJHpBB8"
   },
   "outputs": [],
   "source": [
    "# 형태소 분석 및 전처리\n",
    "def text_preprocessing(text_list):\n",
    "    tokenizer = Mecab() #형태소 분석기\n",
    "\n",
    "    token_list = [] \n",
    "    \n",
    "    for text in text_list:\n",
    "        txt = re.sub(\"[a-zA-Z0-9]\", ' ', text) #영문, 숫자 제거 -> 특수문자는 제거하지 않음\n",
    "        txt = re.sub('[가-힣]+\\s기자','기자', txt) #기자 이름 제거\n",
    "        token = tokenizer.morphs(txt) #형태소 분석\n",
    "\n",
    "        token = [t for t in token] \n",
    "        token_list.append(token)\n",
    "        \n",
    "    return token_list, tokenizer\n",
    "\n",
    "test['new_article'], mecab = text_preprocessing(test['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZYYAXVr-Ltf4"
   },
   "outputs": [],
   "source": [
    "# vectorizer\n",
    "test_X_seq = vectorizer.texts_to_sequences(test[\"new_article\"])\n",
    "test_X = pad_sequences(test_X_seq, maxlen = 100) # 길이를 맞춰줌\n",
    "\n",
    "# 새로 생성한 변수와 vectorizer을 concat\n",
    "test_X = np.concatenate([test_X,test[[\"info1_title\",\"info1_content\",\"new_ord\",\"content_startswith_[\"]].values.reshape(-1,4)], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LDjRKT6a_Tx3"
   },
   "source": [
    "# test 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 85825,
     "status": "ok",
     "timestamp": 1609595244455,
     "user": {
      "displayName": "이혜림",
      "photoUrl": "",
      "userId": "03280505858871436290"
     },
     "user_tz": -540
    },
    "id": "_ncycsgEs4jH",
    "outputId": "5f966722-1446-4bad-88b9-f75cc2236eca"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "# lstm 예측값\n",
    "predicted = lstm_model.predict([test_X[:,:100],test_X[:,-4:]], batch_size = 100)\n",
    "\n",
    "# 해당 문장의 예측값과 해당문장의 앞문장, 앞앞문장의 예측값을 feature로 하여 최종 예측 -> lgbm 이용\n",
    "len_predicted = len(predicted)\n",
    "pre_predicted1 = np.array([predicted[idx-1][0] for idx in range(len(predicted))]).reshape(-1,1) # 앞문장 예측값\n",
    "pre_predicted2 = np.array([predicted[idx-2][0] for idx in range(len(predicted))]).reshape(-1,1) # 앞앞문장 예측값\n",
    "test[\"predicted\"]=predicted\n",
    "test[\"pre_predicted1\"]=pre_predicted1\n",
    "test[\"pre_predicted2\"]=pre_predicted2\n",
    "\n",
    "lgbm_final_predicted = lgbm_model.predict(test[[\"predicted\",\"pre_predicted1\",\"pre_predicted2\"]])\n",
    "test[\"info\"]=lgbm_final_predicted\n",
    "\n",
    "# ord가 1,2인 것은 lgbm모델을 위한 feature가 올바르지 않기 때문에 lstm모델 예측값만을 통해 예측(threshold 0.6)\n",
    "test[\"info\"][test[\"ord\"]==1]=(test[\"predicted\"][test[\"ord\"]==1]>=0.6).astype(\"int\")\n",
    "test[\"info\"][test[\"ord\"]==2]=(test[\"predicted\"][test[\"ord\"]==2]>=0.6).astype(\"int\")\n",
    "\n",
    "# 사이트와 결측값의 경우 rule 기반 예측\n",
    "test[\"info\"][test[\"content\"].apply(lambda x: True if ('http://etoday.bujane.co.kr/' in x) or ('http://www.hisl.co.kr/0306/' == x)  or (x==']]') else False)]=1\n",
    "\n",
    "# submission 파일 info에 반영\n",
    "submission[\"info\"]=test['info']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v7DbnN9U8PY-"
   },
   "outputs": [],
   "source": [
    "print(time.time() - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8Uogbhja7e2t"
   },
   "source": [
    "# 제출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xn1FyB3A7dnS"
   },
   "outputs": [],
   "source": [
    "# 최종 submission file 제출\n",
    "submission.to_csv(\"/content/submission.csv\", encoding=\"utf-8-sig\",index=False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "prediction_code",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
